{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "import silero_vad.silero_vad.utils as utils\n",
    "import silero_vad.silero_vad.model as vad_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(vad_model)\n",
    "\n",
    "from silero_vad.silero_vad.model import VoiceActivityDetection, VoiceActivityDetection_V5\n",
    "from audiochains.streams import InputStream, StreamFromFile\n",
    "from audiochains.writers import WriterInWAV\n",
    "from audiochains.block_methods import RMSFromBytes, UnpackRawInInt16, UnpackRawInFloat32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path('./silero_vad/silero_vad/files/silero_vad.onnx').is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VoiceActivityDetection(\n",
    "    samplerate=16000,\n",
    "    onnx_filepath='./silero_vad/silero_vad/files/silero_vad.onnx',\n",
    "    # num_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v5 = VoiceActivityDetection_V5(\n",
    "    samplerate=16000,\n",
    "    onnx_filepath='./silero_vad/silero_vad/files/silero_vad_v5.onnx',\n",
    "    # num_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UnpackRawInFloat64(BlockAudioMethod):\n",
    "#     \"\"\"\n",
    "#     Unpacking raw audio data (sequences of bytes) in the numpy float32 array.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __call__(self, in_data: bytes) -> np_float32_array:\n",
    "#         max_int16_value = 2 ** 15\n",
    "#         data = np.frombuffer(in_data, np.int16)\n",
    "#         return data.astype(np.float32) / max_int16_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7193], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1).to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAD failed with exception: Input audio chunk is too short\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "blocksize = 512\n",
    "sampwidth = 2\n",
    "\n",
    "\n",
    "with StreamFromFile(\n",
    "    filename='samples/учитель_дети_вырезка.wav',\n",
    "    blocksize=blocksize\n",
    ") as stream, WriterInWAV(\n",
    "    file_name='samples_processed/processed.wav',\n",
    "    framerate=stream.samplerate,\n",
    "    channels=stream.channels,\n",
    "    sampwidth=sampwidth\n",
    ") as writer:\n",
    "    stream.set_methods(\n",
    "        UnpackRawInFloat32()\n",
    "    )\n",
    "    for _ in range(stream.get_iterations()):\n",
    "        try:\n",
    "            raw_data = stream.read(blocksize)\n",
    "            confidence = model_v5(\n",
    "                torch.from_numpy(stream.chain_of_methods(raw_data)), 16000\n",
    "                ).item()\n",
    "            if confidence >= threshold:\n",
    "                writer.write(raw_data)\n",
    "            else:\n",
    "                writer.write(bytearray([0] * blocksize * 2))\n",
    "        except Exception as err:\n",
    "            print(f'VAD failed with exception: {err}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(Path('samples/').iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'папа'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples\\будем_говорить_протяжно.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\виноград_1.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\виноград_2.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\виноград_скажи.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\говорят_о.wav in progres ...\n",
      "VAD failed with exception: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)\n",
      "samples\\дети_мычат.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\загадкиwav.wav in progres ...\n",
      "VAD failed with exception: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)\n",
      "samples\\звук_с.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\звуки.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\Люба_не_помогай.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\ноябрь.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\октябрь.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\октябрь_вместе.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\осенние_месяцы.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\осень.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\папа.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\ребенок_говорит_гранит.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учим_корову.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_говорит2wav.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_говорит_3.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_говорит_ваня.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_говорит_музыка.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_дети_вырезка.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_и_Варя.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_и_ребенок.wav in progres ...\n",
      "VAD failed with exception: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)\n",
      "samples\\учитель_папа.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_ребенок_лопата.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_ребенок_машина.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_ребенок_самолет.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_ребенок_собака.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\учитель_скажи_виноград_мычание.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n",
      "samples\\э_ребенка_в_конце.wav in progres ...\n",
      "VAD failed with exception: Input audio chunk is too short\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.125\n",
    "blocksize = 512\n",
    "sampwidth = 2\n",
    "\n",
    "for audio_file_path in Path('samples/').iterdir():\n",
    "    print(f'{audio_file_path} in progres ...')\n",
    "    with StreamFromFile(\n",
    "        filename=str(audio_file_path),\n",
    "        blocksize=blocksize\n",
    "    ) as stream, WriterInWAV(\n",
    "        file_name=f'samples_processed/{audio_file_path.stem}_processed.wav',\n",
    "        framerate=stream.samplerate,\n",
    "        channels=stream.channels,\n",
    "        sampwidth=sampwidth\n",
    "    ) as writer:\n",
    "        stream.set_methods(\n",
    "            UnpackRawInFloat32()\n",
    "        )\n",
    "        for _ in range(stream.get_iterations()):\n",
    "            try:\n",
    "                raw_data = stream.read(blocksize)\n",
    "                confidence = model_v5(\n",
    "                    torch.from_numpy(stream.chain_of_methods(raw_data)), 16000\n",
    "                    ).item()\n",
    "                if confidence >= threshold:\n",
    "                    writer.write(raw_data)\n",
    "                else:\n",
    "                    writer.write(bytearray([0] * blocksize * 2))\n",
    "            except Exception as err:\n",
    "                print(f'VAD failed with exception: {err}')\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from IPython import display as disp\n",
    "\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav[:, :1024].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pretrained.dns64()\n",
    "wav, sr = torchaudio.load('SA1.WAV.wav')\n",
    "wav = wav[:, :1024]\n",
    "wav = convert_audio(wav, sr, model.sample_rate, model.chin)\n",
    "with torch.no_grad():\n",
    "    denoised = model(wav[None])[0]\n",
    "disp.display(disp.Audio(wav.data.cpu().numpy(), rate=model.sample_rate))\n",
    "disp.display(disp.Audio(denoised.data.cpu().numpy(), rate=model.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wave\n",
    "\n",
    "file = wave.open('SA1.WAV.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.frombuffer(file.readframes(1024), np.int16).astype(np.float32) / 2**15\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0259, 0.0278]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.from_numpy(arr), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024627722799777985"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from silero_vad.utils_vad import init_jit_model\n",
    "\n",
    "model_jit = init_jit_model(\n",
    "    model_path='silero_vad/files/silero_vad.jit'\n",
    ")\n",
    "\n",
    "model_jit(torch.from_numpy(arr), 16000).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
